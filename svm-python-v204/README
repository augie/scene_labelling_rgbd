INSTALLATION:

Run make.


TRAINING AND CLASSIFICATION:

1) Create a new directory with an appropriate name in ./work/
2) Generate and put in the new directory files with the following names and formats:

   a) data_nodefeats.txt
        Description: node features file.
	Format: - the header starts with @DATA on a new line, everything above it is ignored.
	      	- lines starting with # are treated as comments.
		- data lines are the following fields which are tab separated: scene_number segment_number label feature1 feature2 .. feature<n>

   b) data_edgefeats.txt
	Description: edge features file.
	Format: - the header starts with @DATA on a new line, everything above it is ignored
	      	- lines starting with # are treated as comments
		- data lines are the following fields which are tab separated: scene_number segment_1_number segment_2_number label_1 label_2 feature1 feature2 .. feature<n>  

   c) labelmap.txt
	Description: mapping from the linenumber of labels.txt to the label number used by the classifer.

   d) objectmap.txt
        Description: ?

3) Change your current working directory (cd) to the new directory you created.
4) From the svm-python-v204 direction, run ./initialize.sh {WORK DIRECTORY WITHOUT ENDING '/'}
5) Add to each of the test# and train# files in each of the fold# folders the location of the appropriate datas_*.txt files.
	
	Example file where the created directory was homedata
	$ cat fold1/test1 
	/opt/ros/diamondback/stacks/scene_labelling_rgbd/svm-python-v204/homedata/datas_14.txt
	/opt/ros/diamondback/stacks/scene_labelling_rgbd/svm-python-v204/homedata/datas_17.txt
	/opt/ros/diamondback/stacks/scene_labelling_rgbd/svm-python-v204/homedata/datas_18.txt
	/opt/ros/diamondback/stacks/scene_labelling_rgbd/svm-python-v204/homedata/datas_19.txt

6) Run ../../run_sequential.sh or ../../run_parallel.sh to train and test a classifier.



OTHER INFO:

svmstruct_mrf Specific Options:
         --m module_name   ->  the module name, which is 'svmstruct_mrf'
		 --lm learning_method -> the learning method (default : objassoc):
								objassoc : the parsimonious model 
								nonassoc : the non associative model
		 --omf object_map_file -> the location of the object mapping file to be used
		 --amf attribute_map_file -> the location of the attribute mapping file
		 --cm classify_method -> the classification method used (default is sum1.IP):
								 sum1 : linear programing using the sum = 1 constraint
								 sum1.IP : use MIP solver using the sum = 1 constraint
								 qbpo : use qbpo method
								 qbpo.sum1.IP : solve using the qbpo method first and initialize the MIP solver with its solution
		 --am attribute_method -> if multiple labeling method is to be used (default false):
								  true: multiple labels for a single instance are allowed
								  false: only one label is allowed
								 

Scripts :
1. initialize.sh : script to generate data files in the correct format 
2. filter.pl : removes the headers from the feature files.
3. normalize.m : normailzes the feature values
4. binfeats.m : bins the features into 10 bins
5. getBinStumps.m :  a function used by binfeats.m 
6. format.pl : reads the data_nodefeats.b.txt and data_edgefeats.b.txt files and generates the one datas_<n>.txt file per scene in the svmstruct input format.
7. clean.sh : cleaning script which removes all the files generated by initialize script and the learn/classify scripts.
8. run_sequential.sh : runs the learner and classifier for all the folds sequentially and agregates the metrics over all folds.
9. run_parallel.sh : runs all the folds parallely and agregates the metrics over all folds. 
